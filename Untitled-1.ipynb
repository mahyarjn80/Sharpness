{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting training...\n",
      "\n",
      "Epoch: 1/20\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "derivative for aten::_scaled_dot_product_flash_attention_for_cpu_backward is not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 407\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_epoch(model, testloader, criterion, device)\n\u001b[1;32m    410\u001b[0m     epoch_train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[2], line 280\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, trainloader, criterion, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    279\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 280\u001b[0m     top_eigs \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_top_eigenvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     step_top_eigenvalues\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m: current_step,\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigenvalues\u001b[39m\u001b[38;5;124m'\u001b[39m: top_eigs,\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    285\u001b[0m     })\n\u001b[1;32m    287\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[2], line 244\u001b[0m, in \u001b[0;36mcompute_top_eigenvalues\u001b[0;34m(model, inputs, labels, criterion, num_iterations)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# Compute Hessian-vector product\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     Hv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(v)\n\u001b[0;32m--> 244\u001b[0m     grad_grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_vector\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     Hv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([gg\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m gg \u001b[38;5;129;01min\u001b[39;00m grad_grads])\n\u001b[1;32m    246\u001b[0m     v_new \u001b[38;5;241m=\u001b[39m Hv \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(Hv)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/autograd/__init__.py:496\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    492\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    493\u001b[0m         grad_outputs_\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    507\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    509\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: derivative for aten::_scaled_dot_product_flash_attention_for_cpu_backward is not implemented"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import grad\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "# Use GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Adjusted hyperparameters for CPU training\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 4e-2  # Fixed learning rate\n",
    "PATCH_SIZE = 4\n",
    "NUM_CLASSES = 10\n",
    "EMBED_DIM = 256\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 4\n",
    "MLP_DIM = 256 * 4\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# [Previous PatchEmbedding and ViT class definitions remain the same]\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=4, in_channels=3, embed_dim=256):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "        \n",
    "        self.proj = nn.Conv2d(\n",
    "            in_channels,\n",
    "            embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, E, H', W')\n",
    "        x = x.flatten(2)  # (B, E, N)\n",
    "        x = x.transpose(1, 2)  # (B, N, E)\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size=32,\n",
    "        patch_size=4,\n",
    "        in_channels=3,\n",
    "        num_classes=10,\n",
    "        embed_dim=256,\n",
    "        num_layers=4,\n",
    "        num_heads=8,\n",
    "        mlp_dim=256*4,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Patch Embedding\n",
    "        self.patch_embed = PatchEmbedding(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_channels=in_channels,\n",
    "            embed_dim=embed_dim,\n",
    "        )\n",
    "        \n",
    "        # Add position embedding\n",
    "        n_patches = (img_size // patch_size) ** 2\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, n_patches + 1, embed_dim))\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # MLP Head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Initialize patch embedding\n",
    "        nn.init.normal_(self.pos_embed, std=0.02)\n",
    "        nn.init.normal_(self.cls_token, std=0.02)\n",
    "        nn.init.normal_(self.patch_embed.proj.weight, std=0.02)\n",
    "        nn.init.zeros_(self.patch_embed.proj.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Create patches\n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        # Add cls token\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        \n",
    "        # Add position embedding\n",
    "        x = x + self.pos_embed\n",
    "        \n",
    "        # Apply transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Get cls token\n",
    "        x = x[:, 0]\n",
    "        \n",
    "        # MLP head\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "\n",
    "# # [Previous training and testing functions remain the same]\n",
    "# def train_epoch(model, trainloader, criterion, optimizer, device, epoch):\n",
    "#     global current_step\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "    \n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         current_step += 1\n",
    "#         inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         step_train_losses.append(loss.item())\n",
    "#         step_numbers.append(current_step)\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "#         if i % 50 == 49:\n",
    "#             avg_loss = running_loss / 50\n",
    "#             accuracy = 100. * correct / total\n",
    "#             print(f'Epoch: {epoch+1}, Batch: {i+1}, Step: {current_step}, Loss: {avg_loss:.3f}, Acc: {accuracy:.2f}%')\n",
    "#             running_loss = 0.0\n",
    "#             plot_training_progress()\n",
    "    \n",
    "#     return running_loss/len(trainloader), 100.*correct/total\n",
    "\n",
    "\n",
    "\n",
    "def test_epoch(model, testloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return test_loss/len(testloader), 100.*correct/total\n",
    "\n",
    "# # [Previous plotting functions remain the same]\n",
    "# def plot_training_progress():\n",
    "#     plt.figure(figsize=(12, 4))\n",
    "    \n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(step_numbers, step_train_losses, 'b-', alpha=0.3, label='Step Loss')\n",
    "    \n",
    "#     window_size = len(step_train_losses)\n",
    "#     if window_size > 0:\n",
    "#         cumulative_means = np.cumsum(step_train_losses) / np.arange(1, window_size + 1)\n",
    "#         plt.plot(step_numbers, cumulative_means, 'r-', \n",
    "#                 label='Mean Loss (to current step)')\n",
    "    \n",
    "#     plt.xlabel('Optimization Step')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "#     plt.title('Training Loss per Step')\n",
    "#     plt.grid(True, alpha=0.3)\n",
    "    \n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.hist(step_train_losses, bins=50, alpha=0.75, color='blue')\n",
    "#     plt.xlabel('Loss Value')\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.title('Loss Distribution')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     Path('results').mkdir(exist_ok=True)\n",
    "#     plt.savefig('results/training_progress.png')\n",
    "#     plt.close()\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "step_train_losses = []\n",
    "step_numbers = []\n",
    "current_step = 0\n",
    "step_top_eigenvalues = []\n",
    "\n",
    "# New function to compute top 3 eigenvalues using power iteration\n",
    "def compute_top_eigenvalues(model, inputs, labels, criterion, num_iterations=100):\n",
    "    \"\"\"\n",
    "    Approximates top 3 eigenvalues of the Hessian using power iteration\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    n_params = sum(p.numel() for p in params)\n",
    "    \n",
    "    # Compute loss and gradients\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    grads = grad(loss, params, create_graph=True)\n",
    "    grad_vector = torch.cat([g.flatten() for g in grads])\n",
    "    \n",
    "    top_eigenvalues = []\n",
    "    v = torch.randn(n_params, device=device)\n",
    "    \n",
    "    # Estimate top 3 eigenvalues\n",
    "    for _ in range(3):\n",
    "        v = v / torch.norm(v)\n",
    "        \n",
    "        # Power iteration\n",
    "        for _ in range(num_iterations):\n",
    "            # Compute Hessian-vector product\n",
    "            Hv = torch.zeros_like(v)\n",
    "            grad_grads = grad(grad_vector @ v, params, retain_graph=True)\n",
    "            Hv = torch.cat([gg.flatten() for gg in grad_grads])\n",
    "            v_new = Hv / torch.norm(Hv)\n",
    "            v = v_new\n",
    "        \n",
    "        # Rayleigh quotient\n",
    "        Hv = torch.zeros_like(v)\n",
    "        grad_grads = grad(grad_vector @ v, params, retain_graph=True)\n",
    "        Hv = torch.cat([gg.flatten() for gg in grad_grads])\n",
    "        eigenvalue = (v @ Hv) / (v @ v)\n",
    "        top_eigenvalues.append(eigenvalue.item())\n",
    "        \n",
    "        # Deflation: remove component in direction of current eigenvector\n",
    "        grad_vector = grad_vector - (grad_vector @ v) * v\n",
    "    \n",
    "    return top_eigenvalues\n",
    "\n",
    "# Modified train_epoch function\n",
    "def train_epoch(model, trainloader, criterion, optimizer, device, epoch):\n",
    "    global current_step\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        current_step += 1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Compute top 3 eigenvalues (every 50 batches to save computation)\n",
    "        if i % 50 == 0:\n",
    "            start_time = time.time()\n",
    "            top_eigs = compute_top_eigenvalues(model, inputs, labels, criterion)\n",
    "            step_top_eigenvalues.append({\n",
    "                'step': current_step,\n",
    "                'eigenvalues': top_eigs,\n",
    "                'time': time.time() - start_time\n",
    "            })\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        step_train_losses.append(loss.item())\n",
    "        step_numbers.append(current_step)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if i % 50 == 49:\n",
    "            avg_loss = running_loss / 50\n",
    "            accuracy = 100. * correct / total\n",
    "            print(f'Epoch: {epoch+1}, Batch: {i+1}, Step: {current_step}, Loss: {avg_loss:.3f}, Acc: {accuracy:.2f}%')\n",
    "            running_loss = 0.0\n",
    "            plot_training_progress()\n",
    "    \n",
    "    return running_loss/len(trainloader), 100.*correct/total\n",
    "\n",
    "# Modified plot_training_progress function to include eigenvalue plotting\n",
    "def plot_training_progress():\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Original loss plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(step_numbers, step_train_losses, 'b-', alpha=0.3, label='Step Loss')\n",
    "    window_size = len(step_train_losses)\n",
    "    if window_size > 0:\n",
    "        cumulative_means = np.cumsum(step_train_losses) / np.arange(1, window_size + 1)\n",
    "        plt.plot(step_numbers, cumulative_means, 'r-', \n",
    "                label='Mean Loss')\n",
    "    plt.xlabel('Optimization Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Loss per Step')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss distribution\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(step_train_losses, bins=50, alpha=0.75, color='blue')\n",
    "    plt.xlabel('Loss Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Loss Distribution')\n",
    "    \n",
    "    # Eigenvalue plot\n",
    "    if step_top_eigenvalues:\n",
    "        steps = [e['step'] for e in step_top_eigenvalues]\n",
    "        eig1 = [e['eigenvalues'][0] for e in step_top_eigenvalues]\n",
    "        eig2 = [e['eigenvalues'][1] for e in step_top_eigenvalues]\n",
    "        eig3 = [e['eigenvalues'][2] for e in step_top_eigenvalues]\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(steps, eig1, 'r-', label='λ1')\n",
    "        plt.plot(steps, eig2, 'g-', label='λ2')\n",
    "        plt.plot(steps, eig3, 'b-', label='λ3')\n",
    "        plt.xlabel('Optimization Step')\n",
    "        plt.ylabel('Eigenvalue')\n",
    "        plt.legend()\n",
    "        plt.title('Top 3 Hessian Eigenvalues')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    Path('results').mkdir(exist_ok=True)\n",
    "    plt.savefig('results/training_progress.png')\n",
    "    plt.close()\n",
    "\n",
    "# Data transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                     download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                       shuffle=False, num_workers=0)\n",
    "\n",
    "# Create results directory\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "Path('results/checkpoints').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model = torchvision.models.vit_b_16(\n",
    "    image_size=32,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    weights=None,  # Training from scratch\n",
    ").to(device)\n",
    "\n",
    "# model = ViT(\n",
    "#     img_size=32,\n",
    "#     patch_size=PATCH_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     embed_dim=EMBED_DIM,\n",
    "#     num_layers=NUM_LAYERS,\n",
    "#     num_heads=NUM_HEADS,\n",
    "#     mlp_dim=MLP_DIM,\n",
    "#     dropout=DROPOUT,\n",
    "# ).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0)  # Normal gradient descent\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "epoch_train_losses = []\n",
    "epoch_train_accuracies = []\n",
    "epoch_test_losses = []\n",
    "epoch_test_accuracies = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'\\nEpoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, trainloader, criterion, optimizer, device, epoch)\n",
    "    test_loss, test_acc = test_epoch(model, testloader, criterion, device)\n",
    "    \n",
    "    epoch_train_losses.append(train_loss)\n",
    "    epoch_train_accuracies.append(train_acc)\n",
    "    epoch_test_losses.append(test_loss)\n",
    "    epoch_test_accuracies.append(test_acc)\n",
    "    \n",
    "    print(f'Epoch Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Epoch Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n",
    "    \n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'test_loss': test_loss,\n",
    "        'step_train_losses': step_train_losses,\n",
    "        'step_numbers': step_numbers\n",
    "    }\n",
    "    torch.save(checkpoint, f'results/checkpoints/epoch_{epoch+1}.pth')\n",
    "\n",
    "# Save final results\n",
    "results = {\n",
    "    'epoch_train_losses': epoch_train_losses,\n",
    "    'epoch_train_accuracies': epoch_train_accuracies,\n",
    "    'epoch_test_losses': epoch_test_losses,\n",
    "    'epoch_test_accuracies': epoch_test_accuracies,\n",
    "    'step_train_losses': step_train_losses,\n",
    "    'step_numbers': step_numbers\n",
    "}\n",
    "\n",
    "with open('results/training_metrics.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "torch.save(model.state_dict(), 'results/vit_cifar10.pth')\n",
    "\n",
    "# Final plots\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_train_losses, label='Train Loss')\n",
    "plt.plot(epoch_test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Test Loss per Epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epoch_test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Training and Test Accuracy per Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/epoch_metrics.png')\n",
    "plt.close()\n",
    "\n",
    "plot_training_progress()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Final Test Accuracy: {epoch_test_accuracies[-1]:.2f}%\")\n",
    "print(\"\\nResults saved in 'results' directory:\")\n",
    "print(\"- Model weights: results/vit_cifar10.pth\")\n",
    "print(\"- Training metrics: results/training_metrics.json\")\n",
    "print(\"- Step-wise loss plot: results/training_progress.png\")\n",
    "print(\"- Epoch metrics plot: results/epoch_metrics.png\")\n",
    "print(\"- Checkpoints: results/checkpoints/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
